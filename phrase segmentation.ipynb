{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/BakerStreetBakery/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = open('./data/1.txt', 'r')\n",
    "text = fs.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'THE ADVENTURES OF SHERLOCK HOLMES\\n\\nby\\n\\nSIR ARTHUR CONAN DOYLE\\n\\n\\n\\n   I. A Scandal in Bohemia\\n  II. Th'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens length 125682\n",
      "words length 102881\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(text)\n",
    "words = [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "print 'tokens length', len(tokens)\n",
    "print 'words length', len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'the',\n",
       " u'adventures',\n",
       " u'of',\n",
       " u'sherlock',\n",
       " u'holmes',\n",
       " u'by',\n",
       " u'sir',\n",
       " u'arthur',\n",
       " u'conan',\n",
       " u'doyle',\n",
       " u'i',\n",
       " u'a',\n",
       " u'scandal',\n",
       " u'in',\n",
       " u'bohemia',\n",
       " u'ii',\n",
       " u'the',\n",
       " u'league',\n",
       " u'iii',\n",
       " u'a',\n",
       " u'case',\n",
       " u'of',\n",
       " u'identity',\n",
       " u'iv',\n",
       " u'the',\n",
       " u'boscombe',\n",
       " u'valley',\n",
       " u'mystery',\n",
       " u'the',\n",
       " u'five',\n",
       " u'orange',\n",
       " u'pips',\n",
       " u'vi',\n",
       " u'the',\n",
       " u'man',\n",
       " u'with',\n",
       " u'the',\n",
       " u'twisted',\n",
       " u'lip',\n",
       " u'vii',\n",
       " u'the',\n",
       " u'adventure',\n",
       " u'of',\n",
       " u'the',\n",
       " u'blue',\n",
       " u'carbuncle',\n",
       " u'viii',\n",
       " u'the',\n",
       " u'adventure',\n",
       " u'of',\n",
       " u'the',\n",
       " u'speckled',\n",
       " u'band',\n",
       " u'ix',\n",
       " u'the',\n",
       " u'adventure',\n",
       " u'of',\n",
       " u'the',\n",
       " u'engineer',\n",
       " u'thumb',\n",
       " u'x',\n",
       " u'the',\n",
       " u'adventure',\n",
       " u'of',\n",
       " u'the',\n",
       " u'noble',\n",
       " u'bachelor',\n",
       " u'xi',\n",
       " u'the',\n",
       " u'adventure',\n",
       " u'of',\n",
       " u'the',\n",
       " u'beryl',\n",
       " u'coronet',\n",
       " u'xii',\n",
       " u'the',\n",
       " u'adventure',\n",
       " u'of',\n",
       " u'the',\n",
       " u'copper',\n",
       " u'beeches',\n",
       " u'adventure',\n",
       " u'i',\n",
       " u'a',\n",
       " u'scandal',\n",
       " u'in',\n",
       " u'bohemia',\n",
       " u'i',\n",
       " u'to',\n",
       " u'sherlock',\n",
       " u'holmes',\n",
       " u'she',\n",
       " u'is',\n",
       " u'always',\n",
       " u'the',\n",
       " u'woman',\n",
       " u'i',\n",
       " u'have',\n",
       " u'seldom',\n",
       " u'heard']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_threshold_tau = 5\n",
    "words_len = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = {}\n",
    "index = {}\n",
    "for i in range(words_len):\n",
    "    word = words[i]\n",
    "    if word not in index.keys():\n",
    "        index[word] = [i]\n",
    "    else:\n",
    "        index[word].append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'writings', u'yellow', u'four', u'woods', u'hanging', u'pardon', u'granting', u'eligible', u'originality', u'lord']\n",
      "[16100, 29961, 41106, 43059, 55336, 62004, 65537, 66533, 71653, 73134, 77788, 93519, 96441]\n"
     ]
    }
   ],
   "source": [
    "print index.keys()[:10]\n",
    "print index[index.keys()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'dad is', u'city the', u'it absolutely', u'bird then', u'dashed down', u'expect the', u'your whole', u'stairs it', u'now when', u'all quarters']\n",
      "[u'that we were', u'down the sheet', u'you are peterson', u'anyone else yes', u'he took it', u'was no more', u'to a clever', u'me with my', u'would be for', u'said i laughing']\n",
      "[u'would not have his', u'he was in dreadful', u'i believe that the', u'that it is still', u'as i have changed', u'more than once observed', u'sherlock holmes was as', u'rushed into the glade', u'if it were guilty', u'to say that a']\n",
      "[u'i would not have his', u'one of the most determined', u'on the other hand if', u'to me to be a', u'one of the most absolute', u'i do not know is', u'i do not think that', u'seemed to me that i', u'the corner of the mantelpiece', u'one of the most lovely']\n",
      "[u'i beg that you will draw', u'i have no doubt that you', u'from one to the other noting', u'from one to the other pausing', u'i have no doubt that he', u'i have no doubt that we', u'i beg that you will question', u'in the direction of the old', u'i do not think that there', u'i do not think that any']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "while len(index.keys()) > 0:\n",
    "    index_p = {}\n",
    "    for j in index.keys():\n",
    "        if len(index[j]) > min_threshold_tau:\n",
    "            f[j] = len(index[j])\n",
    "            for k in index[j]:\n",
    "                if k+1 < words_len:\n",
    "                    new_phrase = j + u' ' + words[k + 1]\n",
    "                    if new_phrase not in index_p.keys():\n",
    "                        index_p[new_phrase] = [k + 1]\n",
    "                    else:\n",
    "                        index_p[new_phrase].append(k + 1)\n",
    "    index = index_p\n",
    "    print index.keys()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4581\n",
      "[u'to me that', u'could not', u'to me and', u'the second', u'give him', u'until at', u'yellow', u'along the', u'four', u'while he']\n"
     ]
    }
   ],
   "source": [
    "print len(f.keys())\n",
    "print f.keys()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrases = []\n",
    "for w in f.keys():\n",
    "    if len(w.split(u' ')) > 1:\n",
    "        phrases.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2887\n",
      "[u'to me that', u'could not', u'to me and', u'the second', u'give him', u'until at', u'along the', u'while he', u'night the', u'the hands']\n"
     ]
    }
   ],
   "source": [
    "print len(phrases)\n",
    "print phrases[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PMI = {}\n",
    "PLK = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_u(phrase, f):\n",
    "    words = phrase.split(u' ')\n",
    "    denom = 0\n",
    "    for j in words:\n",
    "        denom += f[word]\n",
    "    return f[phrase]*1. / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cal_PMI_PLK(phrase, f, pmi, plk):\n",
    "    words = phrase.split(u' ')\n",
    "    prob_whole = prob_u(phrase, f)\n",
    "    if len(words) > 2:\n",
    "        min_mutual_info = float('inf')\n",
    "        best_u_left = None\n",
    "        best_u_right = None\n",
    "        for i in range(1, len(words)):\n",
    "            u_left = u' '.join(words[:i])\n",
    "            u_right = u' '.join(words[i:])\n",
    "            info = math.log(prob_whole * 1. / (prob_u(u_left, f) * prob_u(u_right, f)))\n",
    "            if info < min_mutual_info:\n",
    "                min_mutual_info = info\n",
    "                best_u_left = u_left\n",
    "                best_u_right = u_right\n",
    "    else:\n",
    "        best_u_left = words[0]\n",
    "        best_u_right = words[1]\n",
    "    \n",
    "    pmi[phrase] = math.log(prob_whole * 1. / (prob_u(best_u_left, f) * prob_u(best_u_right, f)))\n",
    "    plk[phrase] = prob_whole * math.log(prob_whole * 1. / (prob_u(best_u_left, f) * prob_u(best_u_right, f)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in phrases:\n",
    "    cal_PMI_PLK(p, f, PMI, PLK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2887\n",
      "to me that\n",
      "-7.51906999331\n",
      "-4.76207766243\n"
     ]
    }
   ],
   "source": [
    "print len(PMI.keys())\n",
    "print PMI.keys()[0]\n",
    "print PMI[PMI.keys()[0]]\n",
    "print PLK[PLK.keys()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informativeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IDF_phrase = {}\n",
    "IDF_word = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the adventures of sherlock holmes\n"
     ]
    }
   ],
   "source": [
    "sentences = text.split('\\n')\n",
    "len(sentences)\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = sentences[i].lower()\n",
    "print sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cal_word_IDF(docs, idf_word):\n",
    "    total_length = len(docs)\n",
    "    for w in words:\n",
    "        count = 0\n",
    "        for d in docs:\n",
    "            if w in d:\n",
    "                count += 1\n",
    "        if count > 0:\n",
    "            idf_word[w] = math.log(total_length * 1. / count)\n",
    "        else:\n",
    "            idf_word[w] = 0\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cal_word_IDF(sentences, IDF_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'writings', u'yellow', u'four', u'woods', u'hanging']\n",
      "9.44604470534\n"
     ]
    }
   ],
   "source": [
    "print IDF_word.keys()[:5]\n",
    "print IDF_word[IDF_word.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_phrase_IDF(phrases, word_idf, phrase_idf):\n",
    "    for p in phrases:\n",
    "        idf = 0\n",
    "        words = p.split(u' ')\n",
    "        for w in words:\n",
    "            idf += word_idf[w]\n",
    "        phrase_idf[p] = idf * 1. / len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cal_phrase_IDF(phrases, IDF_word, IDF_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'to me that', u'could not', u'the second', u'the most', u'led into']\n",
      "1.64791863964\n"
     ]
    }
   ],
   "source": [
    "print IDF_phrase.keys()[:5]\n",
    "print IDF_phrase[IDF_phrase.keys()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for p in phrases:\n",
    "    row = []\n",
    "    row.append(p)\n",
    "    row.append(PMI[p])\n",
    "    row.append(PLK[p]) \n",
    "    row.append(IDF_phrase[p])\n",
    "    data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2887\n",
      "to me that\n",
      "could not\n",
      "to me and\n",
      "the second\n",
      "give him\n",
      "until at\n",
      "along the\n",
      "while he\n",
      "night the\n",
      "the hands\n",
      "and took\n",
      "from the first\n",
      "you see\n",
      "the last\n",
      "that he might\n",
      "the kitchen\n",
      "and of\n",
      "was about to\n",
      "the edge\n",
      "which i was\n",
      "i have already\n",
      "to prevent\n",
      "the neighbourhood\n",
      "i glanced\n",
      "him that\n",
      "me and\n",
      "not know\n",
      "but a\n",
      "which she\n",
      "a day\n",
      "however and\n",
      "as i was\n",
      "took the\n",
      "used to\n",
      "which you have\n",
      "a man of\n",
      "and with the\n",
      "i tell you\n",
      "a cry of\n",
      "nothing to\n",
      "up and down\n",
      "had some\n",
      "it is that\n",
      "of it i\n",
      "i have the\n",
      "is absolutely\n",
      "became a\n",
      "against the\n",
      "the village\n",
      "the room\n",
      "the copper beeches\n",
      "had better\n",
      "not more\n",
      "i had a\n",
      "day i\n",
      "upon which\n",
      "from her\n",
      "it we\n",
      "up his\n",
      "the least\n",
      "it came\n",
      "in his hand and\n",
      "over with\n",
      "my name\n",
      "we got\n",
      "did it\n",
      "they had\n",
      "not been\n",
      "something in\n",
      "in his hands\n",
      "until he\n",
      "and it\n",
      "an opinion\n",
      "sir george burnwell\n",
      "was only a\n",
      "of importance\n",
      "one who\n",
      "to a\n",
      "and if\n",
      "and in\n",
      "house i\n",
      "it seemed\n",
      "george burnwell\n",
      "to meet\n",
      "know what\n",
      "well then\n",
      "room and\n",
      "the other was\n",
      "in his chair\n",
      "am a\n",
      "i fear that\n",
      "him but\n",
      "now it\n",
      "i have no doubt that\n",
      "for his\n",
      "house of\n",
      "you should\n",
      "now if\n",
      "the street\n",
      "appears to be\n",
      "i fear\n",
      "for him\n",
      "in front of\n",
      "now in\n",
      "then it\n",
      "save a\n",
      "at work\n",
      "some small\n",
      "sure that\n",
      "that even\n",
      "and then suddenly\n",
      "i thought it\n",
      "have made\n",
      "a note\n",
      "endeavoured to\n",
      "name of\n",
      "we went\n",
      "the direction\n",
      "you think\n",
      "saw that\n",
      "see you\n",
      "the letter\n",
      "i have had\n",
      "if he\n",
      "copper beeches\n",
      "i felt that\n",
      "was to\n",
      "wish to\n",
      "eyes and\n",
      "it that\n",
      "the dark\n",
      "at that\n",
      "a very\n",
      "had he\n",
      "i hope\n",
      "miss hunter\n",
      "that he would\n",
      "wish you\n",
      "be in\n",
      "cut off\n",
      "your father\n",
      "led to\n",
      "to keep\n",
      "fire and\n",
      "out from\n",
      "going to\n",
      "is that\n",
      "you go\n",
      "have got\n",
      "of the same\n",
      "his face\n",
      "my way\n",
      "in the house\n",
      "have to\n",
      "had listened\n",
      "him the\n",
      "her father\n",
      "you understand\n",
      "you can\n",
      "anything of\n",
      "which has\n",
      "the sight of\n",
      "line of\n",
      "for this\n",
      "your own\n",
      "in our\n",
      "me at the\n",
      "wife and\n",
      "he is\n",
      "in which i\n",
      "he will be\n",
      "heard the\n",
      "few minutes\n",
      "it to the\n",
      "her hand\n",
      "point of\n",
      "either side\n",
      "know the\n",
      "of the case\n",
      "pocket and\n",
      "was so\n",
      "by the way\n",
      "he continued\n",
      "he should\n",
      "that is\n",
      "it would\n",
      "are not\n",
      "he was a\n",
      "if this\n",
      "take it\n",
      "with their\n",
      "i presume\n",
      "my mind\n",
      "i have been\n",
      "was quite\n",
      "told you\n",
      "refused to\n",
      "above the\n",
      "holmes laughing\n",
      "into an\n",
      "from my\n",
      "shrugged his\n",
      "which i\n",
      "to do\n",
      "the afternoon\n",
      "which a\n",
      "head and\n",
      "the man who\n",
      "man was\n",
      "is always\n",
      "in an instant\n",
      "may have been\n",
      "he that\n",
      "i found myself\n",
      "light of\n",
      "where the\n",
      "all the other\n",
      "save the\n",
      "think that i\n",
      "it was not\n",
      "at the time of\n",
      "ah yes\n",
      "over this\n",
      "is to\n",
      "edge of\n",
      "had passed\n",
      "lady and\n",
      "trust that\n",
      "will leave\n",
      "cab and\n",
      "than i\n",
      "have been\n",
      "and he\n",
      "over the\n",
      "is he\n",
      "that our\n",
      "the lascar\n",
      "have a\n",
      "a light\n",
      "they have\n",
      "his eyes\n",
      "think watson\n",
      "and it is\n",
      "that you should\n",
      "the bottom\n",
      "could be\n",
      "about that\n",
      "could not help\n",
      "to have a\n",
      "the face\n",
      "whom i\n",
      "the more\n",
      "assure you\n",
      "with a very\n",
      "the city\n",
      "no more\n",
      "so there\n",
      "i thought\n",
      "to find\n",
      "so we\n",
      "the wind\n",
      "when i came\n",
      "of you\n",
      "he and\n",
      "the night\n",
      "holmes was\n",
      "i trust\n",
      "piece of\n",
      "just now\n",
      "the small\n",
      "a strong\n",
      "saw a\n",
      "with him\n",
      "i am afraid that\n",
      "see that\n",
      "at any\n",
      "i sat\n",
      "such an\n",
      "i saw\n",
      "morning i\n",
      "i say\n",
      "i started\n",
      "was a\n",
      "it might\n",
      "which will\n",
      "such as\n",
      "that i should\n",
      "i should be\n",
      "me it\n",
      "of a\n",
      "part of\n",
      "that this\n",
      "i understand\n",
      "sorry to\n",
      "the police\n",
      "me if\n",
      "my sister\n",
      "me he\n",
      "a little\n",
      "me in\n",
      "the left\n",
      "all about\n",
      "was i\n",
      "us in\n",
      "endeavouring to\n",
      "that is the\n",
      "his own\n",
      "to you i\n",
      "was nothing\n",
      "i wish\n",
      "day before\n",
      "him for he\n",
      "a week\n",
      "of our\n",
      "on the contrary\n",
      "the loss of\n",
      "a single\n",
      "as much\n",
      "i would not have\n",
      "the young man\n",
      "put on\n",
      "shall be\n",
      "my own\n",
      "i must\n",
      "just a little\n",
      "which it\n",
      "in the evening\n",
      "she cried\n",
      "do you know\n",
      "being a\n",
      "that was\n",
      "when the\n",
      "for some time\n",
      "at a\n",
      "i met him\n",
      "it did\n",
      "want to\n",
      "that we are\n",
      "then he\n",
      "door i\n",
      "out upon the\n",
      "a ring\n",
      "which had\n",
      "the singular\n",
      "on monday\n",
      "i took the\n",
      "i think that\n",
      "i am very\n",
      "for me\n",
      "brixton road\n",
      "was never\n",
      "the business\n",
      "well i\n",
      "the king of\n",
      "we are\n",
      "to make\n",
      "am sorry\n",
      "his manner\n",
      "has a\n",
      "caused by\n",
      "the corner\n",
      "if you\n",
      "that you are\n",
      "the fact that\n",
      "i may\n",
      "believe that\n",
      "and all\n",
      "within the\n",
      "and with a\n",
      "been so\n",
      "he would\n",
      "it would be\n",
      "the colour\n",
      "i came down\n",
      "what the\n",
      "the adventure of\n",
      "i have told\n",
      "came down\n",
      "the window and\n",
      "speak to\n",
      "the body\n",
      "looking at\n",
      "quite so\n",
      "it a\n",
      "can you\n",
      "the lamp\n",
      "his room\n",
      "it i\n",
      "the great\n",
      "so that i\n",
      "is his\n",
      "have no doubt that\n",
      "her at\n",
      "he could\n",
      "my word\n",
      "it is true\n",
      "out into the\n",
      "his hands\n",
      "the nature of the\n",
      "you have been\n",
      "excuse me\n",
      "to us\n",
      "a quiet\n",
      "which led\n",
      "man who\n",
      "as though\n",
      "if you are\n",
      "us and\n",
      "us with\n",
      "you be\n",
      "miss stoper\n",
      "i am so\n",
      "of those\n",
      "that your\n",
      "and when i\n",
      "each other\n",
      "come in\n",
      "that we shall\n",
      "my face\n",
      "came in\n",
      "been in\n",
      "the door of\n",
      "had an\n",
      "had nothing\n",
      "attempt to\n",
      "i not\n",
      "an american\n",
      "for a few\n",
      "in order to\n",
      "miss mary\n",
      "the only\n",
      "that i had\n",
      "to them\n",
      "to it\n",
      "after a\n",
      "now he\n",
      "let us\n",
      "a matter\n",
      "when i have\n",
      "than to\n",
      "young mccarthy\n",
      "the name\n",
      "right and\n",
      "way i\n",
      "he but\n",
      "which led to\n",
      "the gloom\n",
      "over to\n",
      "and have\n",
      "anyone else\n",
      "my friend and\n",
      "in every\n",
      "towards the\n",
      "was just\n",
      "in the room\n",
      "i remarked\n",
      "two days\n",
      "any other\n",
      "it is so\n",
      "spite of\n",
      "i suppose that\n",
      "we drove\n",
      "name is\n",
      "we sat\n",
      "opium den\n",
      "she said\n",
      "that you will\n",
      "the window\n",
      "very much\n",
      "it up\n",
      "have had a\n",
      "and they\n",
      "the inside\n",
      "of being\n",
      "i do not think that\n",
      "to be found\n",
      "of their\n",
      "and then\n",
      "on the other\n",
      "top of\n",
      "i could see\n",
      "me no\n",
      "the cellar\n",
      "no no\n",
      "the impression\n",
      "i could see that\n",
      "shrugged his shoulders\n",
      "the study\n",
      "the words\n",
      "among the\n",
      "or so\n",
      "coronet in\n",
      "watson said\n",
      "you did\n",
      "with his head\n",
      "and on\n",
      "remember that\n",
      "down into\n",
      "shall i\n",
      "the maid\n"
     ]
    }
   ],
   "source": [
    "print len(data)\n",
    "for j in range(500):\n",
    "    print data[j][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
